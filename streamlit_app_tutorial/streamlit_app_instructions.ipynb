{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e835c814-bd96-4b90-9078-6db47784ad52",
   "metadata": {},
   "source": [
    "## Building and Deploying a Streamlit App for Maching Learning\n",
    "In this tutorial, we walk through how you can build and deploy a visual front-end to your machine learning applications. \n",
    "We will use [streamlit](https://docs.streamlit.io/library/get-started/main-concepts), which an easy-to-use framework for creating interactive visualizations and applications in Python (this is in contrast to [plotly dash](https://dash.plotly.com) which, although technically python, relies a lot on HTML and CSS knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf95bf4-c2db-43e8-a81c-0cec57b980c5",
   "metadata": {},
   "source": [
    "### Installing Streamlit and Making a Virtual Environment \n",
    "When we make a new front-end application, we want to use a virtual environment. [Pipenv](https://pipenv-fork.readthedocs.io/en/latest/) will be our tool of choice. Pipenv makes it easy to combine both requirements management and virtual environments at the same time.\n",
    "\n",
    "First, move into the project directory:\n",
    "\n",
    "`cd my_project`\n",
    "\n",
    "Then, run:\n",
    "\n",
    "`pipenv shell` \n",
    "to activate the pipenv.\n",
    "\n",
    "That's all you have to do! \n",
    "\n",
    "After that, when you install packages via `pipenv install [package_name]`, they will be automatically added to your `Pipfile.lock`. No need to update a requirements file all the time!\n",
    "\n",
    "NOTE: This step is *VERY* important for being able to successfully deploy your app later on! Make sure you don't forget this step!!! \n",
    "\n",
    "Note: if using pycharm, it can be helpful to use [these steps](https://stackoverflow.com/questions/46251411/how-do-i-properly-setup-pipenv-in-pycharm) to make sure you're using the virtual environment when running your code in pycharm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058faf86-20b0-407a-9b13-90607e6ccdf6",
   "metadata": {},
   "source": [
    "### Starting up the App\n",
    "Open the file entitled `streamlit_app.py`.\n",
    "\n",
    "Here you have a basic skeleton of an application. This code will simply display a table with 2 columns.\n",
    "\n",
    "\n",
    "<img src=\"./images/code_snippet_1.png\" width=\"300\"/>\n",
    "Code of the basic app.\n",
    "\n",
    "\n",
    "We run the app using the following command:\n",
    "\n",
    "`streamlit run streamlit_app.py`\n",
    "\n",
    "This command opens a new browser window with our streamlit app running. The great thing about streamlit is that the app will be automatically updated whenever we save the file. \n",
    "\n",
    "Running the command, we see the following output in the browser:\n",
    "<img src=\"./images/app_screenshot_1.png\" width=\"300\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd4d2d-9bbc-4699-9f79-58cd251e9a75",
   "metadata": {},
   "source": [
    "### Working with real data \n",
    "Here, we will import the actual Telco churn data and use it as an example for making a streamlit application to deploy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b8843-3cdd-4588-813b-5527a8c209ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "\n",
    "# importing customer churn data\n",
    "data = pd.read_csv(\"./data/training_data.csv\", index_col=0)\n",
    "st.write(\"Churn Data\")\n",
    "st.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27174323-98c5-4db2-bc0b-f3c45eb27cf9",
   "metadata": {},
   "source": [
    "Note: look at what happens when you replace the line\n",
    "`st.write(data)` in the code above with `st.table(data)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f46fd-6a7c-460b-bbe7-1f8478acd116",
   "metadata": {},
   "source": [
    "Now, our streamlit app looks like this:\n",
    "\n",
    "<img src=\"./images/app_screenshot_2.png\" width=\"300\"/>\n",
    "\n",
    "Note that it shows the entire dataframe, and we can even move around to explore the columns and rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7c769f-f3f2-4e65-825b-ec1361100117",
   "metadata": {},
   "source": [
    "### Adding Elements\n",
    "Now, we will explore adding more elements to our app and making some visualizations. \n",
    "\n",
    "We'll start how we should always start in a new DS project: by visualizing the target.\n",
    "\n",
    "Add the code in the next cell to your streamlit app, underneath the dataset visualization. You'll now see a nice bar chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876e15a-698c-4a47-b520-2a6fde53f5b1",
   "metadata": {},
   "source": [
    "<img src=\"./images/app_screenshot_3.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256507c8-a6ae-46a6-9d03-10b1aca6b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.write(\"How many customers in the dataset churned?\")\n",
    "target_bins = data.loc[:, 'Churn'].value_counts()\n",
    "st.bar_chart(target_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1378fee-8862-4e80-94a8-28eef1a75f9e",
   "metadata": {},
   "source": [
    "#### Exercise \n",
    "Add some new elements to your application. Look in the [streamlit documentation](https://docs.streamlit.io/library/api-reference/widgets/st.selectbox).\n",
    "\n",
    "You can use the cells below to save your code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81398f28-7a48-43ef-b487-f634e53665d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c20db9-bcef-4ddf-b5db-76a827820a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f926539-5da9-4a71-a785-bfc37d45524f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55f91191-75e0-47ca-b7d2-620078659688",
   "metadata": {},
   "source": [
    "### Making the Prediction App\n",
    "Here, we will look at integrating machine learning models into the application, and making predicitons. We will update the code in our file `streamlit_app.py` so that it no longer just shows analysis, but full code. \n",
    "\n",
    "First, we will train a model. The code below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef1b934-db93-4f11-ae1a-ab6cd6f6a96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9132fcb6-6d9d-4ec8-83e6-67cad05fce37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training data\n",
    "train = pd.read_csv(\"./data/training_data.csv\")\n",
    "# drop customer ID: not a feature for training \n",
    "train.drop(\"customerID\", axis=1, inplace=True)\n",
    "\n",
    "# getting validation data\n",
    "val = pd.read_csv(\"./data/validation_data.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Data Pre-Processing\n",
    "\n",
    "The following columns need to be fixed in order to train the model:\n",
    "1. All yes/no categories category encoded\n",
    "2. All category columns category encoded\n",
    "3. \"Churn\" column category encoded\n",
    "\"\"\"\n",
    "\n",
    "categorical_columns = ['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n",
    "       'PhoneService', 'MultipleLines', 'InternetService',\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "       'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling',\n",
    "       'PaymentMethod', 'Churn']\n",
    "# converting all the categorical columns to numeric\n",
    "col_mapper = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train.loc[:, col])\n",
    "    class_names = le.classes_\n",
    "    train.loc[:, col] = le.transform(train.loc[:, col])\n",
    "    # saving encoder for each column to be able to inverse-transform later\n",
    "    col_mapper.update({col: le})\n",
    "\n",
    "train.replace(\" \", \"0\", inplace=True)\n",
    "\n",
    "# converting \"Total Charges\" to numeric\n",
    "train.loc[:, \"TotalCharges\"] = pd.to_numeric(train.loc[:, \"TotalCharges\"])\n",
    "\n",
    "# converting data pre-processing steps to a function to apply to new data\n",
    "def pre_process_data(df, label_encoder_dict):\n",
    "    df.drop(\"customerID\", axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col in list(label_encoder_dict.keys()):\n",
    "            column_le = label_encoder_dict[col]\n",
    "            df.loc[:, col] = column_le.transform(df.loc[:, col])\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return df\n",
    "\n",
    "# splitting into X and Y\n",
    "x_train = train.drop(\"Churn\", axis=1)\n",
    "y_train = train.loc[:, \"Churn\"]\n",
    "\n",
    "# fitting model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# pre-processing validation data\n",
    "val = pre_process_data(val, col_mapper)\n",
    "\n",
    "# split validation set \n",
    "x_val = val.drop(\"Churn\", axis=1)\n",
    "y_val = val.loc[:, \"Churn\"]\n",
    "\n",
    "# predicting on validation\n",
    "predictions = model.predict(x_val)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_val, predictions)\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f\"Validation accuracy is: {round(accuracy, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f1b89d-65a7-4cfa-805f-04d9024bc5be",
   "metadata": {},
   "source": [
    "#### Preparing the code for use in the app\n",
    "We need to update the code used for making a prediction. \n",
    "\n",
    "For this, we also need anything that must be applied to the model to make a prediction: like label encoders, and of course the trained model itself. \n",
    "\n",
    "Steps:\n",
    "1. Save the trained model and fitted label encoder after training. They can be saved as a pickle. These will be used later to apply the necessary transformations to new, incoming data. \n",
    "    - How to: add code at the bottom of your training code to save the model and encoder as a pickle\n",
    "\n",
    "2. Update the prediction code to take in new data, apply the saved label encoders and trained model to the new data \n",
    "    - How to: make a file with prediction code that loads the pickled model and label encoders, and applies them to new data. Should return a prediction (or multiple, if it's batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a2ab64-cea3-494a-83ec-9e7753d7c6e3",
   "metadata": {},
   "source": [
    "Step 1: Code for pickling model and label encoder. To be added to the end of the model training code from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e76ddf4-cfcd-49ad-9d33-46762e5f4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling mdl\n",
    "pickler = open(\"churn_prediction_model.pkl\", \"wb\")\n",
    "pickle.dump(model, pickler)\n",
    "pickler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3216fa0-a7eb-4036-a91f-7f29321ce628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling le dict\n",
    "pickler = open(\"churn_prediction_label_encoders.pkl\", \"wb\")\n",
    "pickle.dump(col_mapper, pickler)\n",
    "pickler.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4979ec3-e4e6-42b6-82a6-af6e276b52f4",
   "metadata": {},
   "source": [
    "Step 2: Creating a new prediction file to get predictions for the new data \n",
    "\n",
    "Code for this step is shown in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802459fa-767e-44be-a8c5-c36c6846e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def load_pickles(model_pickle_path, label_encoder_pickle_path):\n",
    "    model_pickle_opener = open(model_pickle_path, \"rb\")\n",
    "    model = pickle.load(model_pickle_opener)\n",
    "\n",
    "    label_encoder_pickle_opener = open(label_encoder_pickle_path, \"rb\")\n",
    "    label_encoder_dict = pickle.load(label_encoder_pickle_opener)\n",
    "\n",
    "    return model, label_encoder_dict\n",
    "\n",
    "\n",
    "def pre_process_data(df, label_encoder_dict):\n",
    "    # df.drop(\"customerID\", axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col in list(label_encoder_dict.keys()):\n",
    "            column_le = label_encoder_dict[col]\n",
    "            df.loc[:, col] = column_le.transform(df.loc[:, col])\n",
    "        else:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_predictions(processed_df, model):\n",
    "    prediction = model.predict(processed_df)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_predictions(test_df):\n",
    "    model_pickle_path = \"./churn_model/churn_prediction_model.pkl\"\n",
    "    label_encoder_pickle_path = \"./churn_model/churn_prediction_label_encoders.pkl\"\n",
    "\n",
    "    model, label_encoder_dict = load_pickles(model_pickle_path,\n",
    "                                             label_encoder_pickle_path)\n",
    "\n",
    "    processed_df = pre_process_data(test_df, label_encoder_dict)\n",
    "    prediction = make_predictions(processed_df, model)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4e7cf-ccd0-4048-8b0f-cbfac7d7b2d3",
   "metadata": {},
   "source": [
    "### Updating the Prediction App to Make Predictions\n",
    "Up to now, our application only showed some analysis of the training data. It didn't interact with the prediction model in any way. \n",
    "\n",
    "Here, we update the application to apply the model, and show the outcome. \n",
    "\n",
    "First, we will do this with a single row of holdout test data. \n",
    "\n",
    "Later, we will update the application further to allow for making predictions in real time and interacting with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c1bb2-7b62-4b03-87a7-da4335a281bc",
   "metadata": {},
   "source": [
    "#### Making predictions on the one-row test dataset \n",
    "The code below shows how the updated model prediction code from above can be applied, together with steamlit, to make an interactive front-end with a prediction button. The app will already load and display the data from the one hold-out customer to predict when it's started up. Then, a button push will activate making the prediction.\n",
    "\n",
    "By updating your `streamlit_app.py` file with the following code, you should see the following picture in your front-end app: \n",
    "\n",
    "<img src=\"./images/app_screenshot_4.png\" width=\"400\"/>\n",
    "\n",
    "NOTE: This is what is shown in the file `simple_prediction_streamlit_app.py`, with a small extension to test on any customer in the holdout dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8c5e5e-40e5-420c-8dfa-ca6d26805cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def load_pickles(model_pickle_path, label_encoder_pickle_path):\n",
    "    model_pickle_opener = open(model_pickle_path, \"rb\")\n",
    "    model = pickle.load(model_pickle_opener)\n",
    "\n",
    "    label_encoder_pickle_opener = open(label_encoder_pickle_path, \"rb\")\n",
    "    label_encoder_dict = pickle.load(label_encoder_pickle_opener)\n",
    "\n",
    "    return model, label_encoder_dict\n",
    "\n",
    "\n",
    "def pre_process_data(df, label_encoder_dict):\n",
    "    df.drop(\"customerID\", axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col in list(label_encoder_dict.keys()):\n",
    "            column_le = label_encoder_dict[col]\n",
    "            df.loc[:, col] = column_le.transform(df.loc[:, col])\n",
    "        else:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_predictions(processed_df, model):\n",
    "    prediction = model.predict(processed_df)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_predictions(test_df):\n",
    "    model_pickle_path = \"./churn_model/churn_prediction_model.pkl\"\n",
    "    label_encoder_pickle_path = \"./churn_model/churn_prediction_label_encoders.pkl\"\n",
    "\n",
    "    model, label_encoder_dict = load_pickles(model_pickle_path,\n",
    "                                             label_encoder_pickle_path)\n",
    "\n",
    "    processed_df = pre_process_data(test_df, label_encoder_dict)\n",
    "    prediction = make_predictions(processed_df, model)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # make the application\n",
    "    st.title(\"Customer Churn Prediction\")\n",
    "    customer_data = pd.read_csv(\"./data/single_row_to_check.csv\")\n",
    "    \n",
    "    # visualizing cutomer's data\n",
    "    st.table(customer_data)\n",
    "\n",
    "    # generate the prediction for the customer\n",
    "    if st.button(\"Predict Churn\"):\n",
    "        pred = generate_predictions(customer_data)\n",
    "        if bool(pred):\n",
    "            st.text(\"Customer will churn!\")\n",
    "        else:\n",
    "            st.text(\"Customer not predicted to churn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad926772-a1c4-430b-91c1-43f95c948cb7",
   "metadata": {},
   "source": [
    "The following code shows an extension for predicting on every customer in the holodout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c0c9be-5050-4c16-a690-23fd966a499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def load_pickles(model_pickle_path, label_encoder_pickle_path):\n",
    "    model_pickle_opener = open(model_pickle_path, \"rb\")\n",
    "    model = pickle.load(model_pickle_opener)\n",
    "\n",
    "    label_encoder_pickle_opener = open(label_encoder_pickle_path, \"rb\")\n",
    "    label_encoder_dict = pickle.load(label_encoder_pickle_opener)\n",
    "\n",
    "    return model, label_encoder_dict\n",
    "\n",
    "\n",
    "def pre_process_data(df, label_encoder_dict):\n",
    "    df.drop(\"customerID\", axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col in list(label_encoder_dict.keys()):\n",
    "            column_le = label_encoder_dict[col]\n",
    "            df.loc[:, col] = column_le.transform(df.loc[:, col])\n",
    "        else:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_predictions(processed_df, model):\n",
    "    prediction = model.predict(processed_df)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_predictions(test_df):\n",
    "    model_pickle_path = \"./churn_model/churn_prediction_model.pkl\"\n",
    "    label_encoder_pickle_path = \"./churn_model/churn_prediction_label_encoders.pkl\"\n",
    "\n",
    "    model, label_encoder_dict = load_pickles(model_pickle_path,\n",
    "                                             label_encoder_pickle_path)\n",
    "\n",
    "    processed_df = pre_process_data(test_df, label_encoder_dict)\n",
    "    prediction = make_predictions(processed_df, model)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # make the application\n",
    "    st.title(\"Customer Churn Prediction\")\n",
    "    st.text(\"Enter customer data.\")\n",
    "    all_customers_training_data = pd.read_csv(\"./data/holdout_data.csv\")\n",
    "    all_customers_data = all_customers_training_data.drop(columns=\"Churn\")\n",
    "    chosen_customer = st.selectbox(\"Select the customer you are speaking to:\", all_customers_training_data.loc[:, \"customerID\"])\n",
    "    chosen_customer_data = all_customers_data.loc[all_customers_data.loc[:, 'customerID']==chosen_customer]\n",
    "    # visualizing cutomer's data\n",
    "    st.table(chosen_customer_data)\n",
    "\n",
    "    # generate the prediction for the customer\n",
    "    if st.button(\"Predict Churn\"):\n",
    "        pred = generate_predictions(chosen_customer_data)\n",
    "        if bool(pred):\n",
    "            st.text(\"Customer will churn!\")\n",
    "        else:\n",
    "            st.text(\"Customer not predicted to churn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a11f3-2678-4d84-a7d6-e02324512fc9",
   "metadata": {},
   "source": [
    "### Updaing App for Online Predictions \n",
    "Now that we've checked and seen that the application is working and able to apply the model and make predictions, we can update it using the user input features from streamlit, to make it so that users can play with the various inputs and see how they change the model output. \n",
    "\n",
    "The updated code for this is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a5b65-7870-4ab7-bbe0-f9111c0e683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "def load_pickles(model_pickle_path, label_encoder_pickle_path):\n",
    "    model_pickle_opener = open(model_pickle_path, \"rb\")\n",
    "    model = pickle.load(model_pickle_opener)\n",
    "\n",
    "    label_encoder_pickle_opener = open(label_encoder_pickle_path, \"rb\")\n",
    "    label_encoder_dict = pickle.load(label_encoder_pickle_opener)\n",
    "\n",
    "    return model, label_encoder_dict\n",
    "\n",
    "\n",
    "def pre_process_data(df, label_encoder_dict):\n",
    "    # df.drop(\"customerID\", axis=1, inplace=True)\n",
    "    for col in df.columns:\n",
    "        if col in list(label_encoder_dict.keys()):\n",
    "            column_le = label_encoder_dict[col]\n",
    "            df.loc[:, col] = column_le.transform(df.loc[:, col])\n",
    "        else:\n",
    "            continue\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_predictions(processed_df, model):\n",
    "    prediction = model.predict(processed_df)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def generate_predictions(test_df):\n",
    "    model_pickle_path = \"./churn_model/churn_prediction_model.pkl\"\n",
    "    label_encoder_pickle_path = \"./churn_model/churn_prediction_label_encoders.pkl\"\n",
    "\n",
    "    model, label_encoder_dict = load_pickles(model_pickle_path,\n",
    "                                             label_encoder_pickle_path)\n",
    "\n",
    "    processed_df = pre_process_data(test_df, label_encoder_dict)\n",
    "    prediction = make_predictions(processed_df, model)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # make the application\n",
    "    st.title(\"Customer Churn Prediction\")\n",
    "    st.text(\"Enter customer data.\")\n",
    "\n",
    "    # making customer data input\n",
    "    gender = st.selectbox(\"Select customer's gender :\",\n",
    "                         ['Female', 'Male'])\n",
    "    senior_citizen_input = st.selectbox('Is customer a senior citizen? :',\n",
    "                                     [\"No\", \"Yes\"])\n",
    "    if senior_citizen_input == \"Yes\":\n",
    "        senior_citizen = 1\n",
    "    else:\n",
    "        senior_citizen = 0\n",
    "    partner = st.selectbox('Does the customer have a partner? :',\n",
    "                             [\"No\", \"Yes\"])\n",
    "    dependents = st.selectbox('Does the customer have dependents? :',\n",
    "                              [\"Yes\", \"No\"])\n",
    "    tenure = st.slider('How many months has the customer been with the company? :',\n",
    "                       min_value=0, max_value=72, value=24)\n",
    "    phone_service = st.selectbox('Does the customer have phone service? :',\n",
    "                             [\"No\", \"Yes\"])\n",
    "    multiple_lines = st.selectbox('Does the customer have multiple lines? :',\n",
    "                                 [\"No\", \"Yes\", \"No phone service\"])\n",
    "    internet_service = st.selectbox('What type of internet service does the customer have? :',\n",
    "                                  [\"No\", \"DSL\", \"Fiber optic\"])\n",
    "    online_security = st.selectbox('Does the customer have online security? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    online_backup = st.selectbox('Does the customer have online backup? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    device_protection = st.selectbox('Does the customer have device protection? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    tech_support = st.selectbox('Does the customer have tech support? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    streaming_tv = st.selectbox('Does the customer have streaming TV? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    streaming_movies = st.selectbox('Does the customer have streaming movies? :',\n",
    "                                  [\"No\", \"Yes\", \"No internet service\"])\n",
    "    contract = st.selectbox('What kind of contract does the customer have? :',\n",
    "                                  [\"Month-to-month\", \"Two year\", \"One year\"])\n",
    "    paperless_billing = st.selectbox('Does the customer have paperless billing? :',\n",
    "                                  [\"No\", \"Yes\"])\n",
    "    payment_method = st.selectbox(\"What is the customer's payment method? :\",\n",
    "                                     [\"Mailed check\", \"Credit card (automatic)\", \"Bank transfer (automatic)\",\n",
    "                                      \"Electronic check\"])\n",
    "    monthly_charges = st.slider(\"What is the customer's monthly charge? :\", min_value=0, max_value=118, value=50)\n",
    "    total_charges = st.slider('What is the total charge of the customer? :', min_value=0, max_value=8600, value=2000)\n",
    "    input_dict = {'gender': gender,\n",
    "                  'SeniorCitizen': senior_citizen,\n",
    "                  'Partner': partner,\n",
    "                  'Dependents': dependents,\n",
    "                  'tenure': tenure,\n",
    "                  'PhoneService': phone_service,\n",
    "                  'MultipleLines': multiple_lines,\n",
    "                  'InternetService': internet_service,\n",
    "                  'OnlineSecurity': online_security,\n",
    "                  'OnlineBackup': online_backup,\n",
    "                  'DeviceProtection': device_protection,\n",
    "                  'TechSupport': tech_support,\n",
    "                  'StreamingTV': streaming_tv,\n",
    "                  'StreamingMovies': streaming_movies,\n",
    "                  'Contract': contract,\n",
    "                  'PaperlessBilling': paperless_billing,\n",
    "                  'PaymentMethod': payment_method,\n",
    "                  'MonthlyCharges': monthly_charges,\n",
    "                  'TotalCharges': total_charges,\n",
    "                  }\n",
    "    input_data = pd.DataFrame([input_dict])\n",
    "\n",
    "    # generate the prediction for the customer\n",
    "    if st.button(\"Predict Churn\"):\n",
    "        pred = generate_predictions(input_data)\n",
    "        if bool(pred):\n",
    "            # making text red if customer will churn\n",
    "            churn_text = '<p style=\"font-family:Courier; color:Red; font-size: 16px;\">Customer will churn!</p>'\n",
    "            st.markdown(churn_text, unsafe_allow_html=True)\n",
    "        else:\n",
    "            # making text green if customer will not churn\n",
    "            not_churn_text = '<p style=\"font-family:Courier; color:Green; font-size: 16px;\">Customer not predicted to churn</p>'\n",
    "            st.markdown(not_churn_text, unsafe_allow_html=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe8250b-b39e-4d9d-afdd-02413d76fbad",
   "metadata": {},
   "source": [
    "Note that there has to be an input for every feature that the model needs to be able to predict. \n",
    "\n",
    "Updating the code in your file `streamlit_app.py` should give you the folowing output:\n",
    "\n",
    "<img src=\"./images/app_screenshot_5.png\" width=\"200\"/>\n",
    "\n",
    "Note the small change in code at the bottom, to add a small bit of HTML to change the color of the output.\n",
    "\n",
    "This code is shown in the file `prediction_streamlit_app.py`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c384a3d-0314-472a-a118-4b9533e56037",
   "metadata": {},
   "source": [
    "### Final Step: Deploying your Streamlit app\n",
    "Deploying your app with streamlit cloud is incredibly easy. Simply follow the steps in the [documentation](https://docs.streamlit.io/streamlit-cloud/get-started#sign-up-for-streamlit-cloud). \n",
    "\n",
    "First, you have to make a free streamlit cloud account, and connect it with your github.\n",
    "\n",
    "Next, make a github repository for deploying your application. It must contain the `Pipfile` and the `Pipfile.lock` that you created by using `pipenv`. With these 2 files in place, and if you always installed any packages using them and made sure to run your application locally with the `pipenv` virtual environment activated, then deployment should be a breeze. \n",
    "\n",
    "Once you have set up your streamlit cloud account, click on \"New Project\" in the top right corner. There, with your github linked, you will simply need to specify:\n",
    "\n",
    "- The name of your repository where the the app is \n",
    "- The branch in your github repository that the deployed app should be linked to (the great thing about streamlit cloud is that your deployed app is automatically updated whenever you push to this branch!)\n",
    "- The name of the file with your streamlit app you want to deploy (mine, in this case, would be `prediction_streamlit_app.py`).\n",
    "\n",
    "The image below shows these steps.\n",
    "\n",
    "<img src=\"./images/deploy-an-app.png\" width=\"500\"/>\n",
    "\n",
    "Then you simply wait, and your app is deployed!! \n",
    "\n",
    "Check out [this link](https://rachelkberryman-churn-predictor-prediction-streamlit-app-coqysw.streamlitapp.com/) to see my deployed application from this project, and the [linked github repository](https://github.com/rachelkberryman/churn_predictor_application)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
